{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Features\"\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see some of **Specification Curve**'s features in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "\n",
    "import matplotlib_inline.backend_inline\n",
    "\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats(\"svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example of using **Specification Curve**. Note that, in the below, we can pass strings or lists of string into the arguments of the class `SpecificationCurve`. The programme then automatically performs all of possible regressions of endogeneous variables on exogeneous variables and controls. The estimate that is picked out is the coefficient on the given combination of endogeneous and exogenous variables (with conditioning on the given controls).\n",
    "\n",
    "If a control variable is categorical, rather than continuous, it will be treated as a fixed effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import specification_curve as sc\n",
    "\n",
    "df = sc.load_example_data1()\n",
    "y_endog = \"y1\"  # endogeneous variable\n",
    "x_exog = \"x1\"  # exogeneous variable\n",
    "controls = [\"c1\", \"c2\", \"group1\", \"group2\"]\n",
    "sco = sc.SpecificationCurve(\n",
    "    df,\n",
    "    y_endog,\n",
    "    x_exog,\n",
    "    controls,\n",
    ")\n",
    "sco.fit()\n",
    "sco.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grey squares (black lines when there are many specifications) show whether a variable is included in a specification or not. Blue or red markers and error bars show whether the coefficient is positive and significant (at the 0.05 level) or red and significant, respectively.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also specify models with the formula API. An example string would be \"y1 | y2 ~ x1 | x2 | x3 + c1 + c2 + c3 | c4\". This would produce a specification curve in which there two endogenous variables, two exogenous variables, two variables that are always included (c1 and c2), and two controls that are included in all possible combinations.\n",
    "\n",
    "Here's an example, for which we first generate some data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Set seed for random numbers\n",
    "seed_for_prng = 78557\n",
    "# prng=probabilistic random number generator\n",
    "prng = np.random.default_rng(seed_for_prng)\n",
    "\n",
    "# generate some fake data\n",
    "n_samples = 1000\n",
    "x_2 = prng.integers(2, size=n_samples)\n",
    "x_1 = prng.random(size=n_samples)\n",
    "x_3 = prng.integers(3, size=n_samples)\n",
    "x_4 = prng.random(size=n_samples)\n",
    "x_5 = x_1 + 0.05 * np.random.randn(n_samples)\n",
    "x_beta = -1 - 3.5 * x_1 + 0.2 * x_2 + 0.3 * x_3  # NB: coefficient is -3.5\n",
    "prob = 1 / (1 + np.exp(-x_beta))\n",
    "y = prng.binomial(n=1, p=prob, size=n_samples)\n",
    "y2 = prng.binomial(n=1, p=prob * 0.98, size=n_samples)\n",
    "df_logit = pd.DataFrame(\n",
    "    [x_1, x_2, x_3, x_4, x_5, y, y2], [\"x_1\", \"x_2\", \"x_3\", \"x_4\", \"x_5\", \"y\", \"y2\"]\n",
    ").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_form = sc.SpecificationCurve(\n",
    "    df_logit, formula=\"y | y2 ~ x_1 | x_5 + x_2 + x_3 | x_4\"\n",
    ")\n",
    "sc_form.fit()\n",
    "sc_form.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that \"x_2\" is included in all specifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving estimates\n",
    "\n",
    "You can retrieve the estimates from the data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sco = sc.SpecificationCurve(df, y_endog, x_exog, controls)\n",
    "sco.fit()\n",
    "sco.df_r.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference under the null\n",
    "\n",
    "Although not everyone is convinced, it may be informative to run some statistical inferences on the specification curve. These ask: considering the full set of reasonable specifications jointly, how inconsistent are the results with the null hypothesis of no effect? You can find more details in [@simonsohn2020specification]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn = sc.load_example_data3()\n",
    "dfn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As normal, we create a specification curve object and fit it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sco = sc.SpecificationCurve(\n",
    "    dfn, y_endog=[\"y1\", \"y2\"], x_exog=\"x1\", controls=[\"c1\", \"c2\", \"c3\"]\n",
    ")\n",
    "sco.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to look at the fit under the null, we can choose to either fit it directly, using `.fit_null()` or to use `.plot(show_null_curve=True)`, which will run the inference automatically *and* plot it. For either case, you can also pass the number of bootstraps as an argument: for example, `.fit_null(n_boot=10)` or .`plot(show_null_curve=True, **{\"n_boot\": 10})` respectively.\n",
    "\n",
    "You should really use a large number of bootstraps (eg 500) but be warned it takes a long time to run this many.\n",
    "\n",
    "Let's fit the null first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sco.fit_null(n_boot=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can plot it to see what the likely range of the coefficient would be under the null:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sco.plot(show_null_curve=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, there is a summary of some statistical tests that are relevant to whether coefficient under the null is zero (hypothesis) or not, and whether the share of positives and negatives is what you would expect from chance or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sco.null_stats_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, once you have done all of this fitting, you can examine it all simply by calling the object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving results to file\n",
    "\n",
    "Save the plot to file (the format is inferred from file extension):\n",
    "\n",
    "```python\n",
    "sco = sc.SpecificationCurve(df, y_endog, x_exog, controls,\n",
    "                                  cat_expand=['group1'])\n",
    "sco.fit()\n",
    "sco.plot(save_path='test_fig.pdf')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expanding a categorical variable\n",
    "\n",
    "Should you need to, you can expand a categorical variable into its different elements and run those separately. In the example below, the `\"group2\"` categorical variable is expanded like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_endog = \"y1\"  # endogeneous variable\n",
    "x_exog = \"x1\"  # exogeneous variable\n",
    "controls = [\"c1\", \"c2\", \"group1\", \"group2\"]\n",
    "sco = sc.SpecificationCurve(\n",
    "    df,\n",
    "    y_endog,\n",
    "    x_exog,\n",
    "    controls,\n",
    "    cat_expand=[\"group2\"],  # have each fixed effect run separately\n",
    ")\n",
    "sco.fit()\n",
    "sco.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using multiple exogeneous variables\n",
    "\n",
    "Sometimes, you'd like to check different independent variables (and the coefficients they come with following a regression). This is achieved by passing a list to the exogeneous argument of `SpecificationCurve`. These variations on the independent variables are labelled by `x` in the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sc.load_example_data1()\n",
    "x_exog = [\"x1\", \"x2\"]\n",
    "y_endog = \"y1\"\n",
    "controls = [\"c1\", \"c2\", \"group1\", \"group2\"]\n",
    "sco = sc.SpecificationCurve(df, y_endog, x_exog, controls)\n",
    "sco.fit()\n",
    "sco.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excluding some combinations of controls\n",
    "\n",
    "Some controls may be redundant, and you might want to exclude them both being used together. The `exclu_grps` keyword argument achieves this.\n",
    "\n",
    "In the below example, `\"c1\"` and `\"c2\"` are never run in the same specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sc.load_example_data1()\n",
    "\n",
    "y_endog = \"y1\"\n",
    "x_exog = \"x1\"\n",
    "controls = [\"c1\", \"c2\", \"group1\", \"group2\"]\n",
    "sco = sc.SpecificationCurve(df, y_endog, x_exog, controls, exclu_grps=[[\"c1\", \"c2\"]])\n",
    "sco.fit()\n",
    "sco.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Always include some controls in all specifications\n",
    "\n",
    "Likewise, there will be times when you always wish to include a particular control in specifications, and to show this on the plot. The `always_include=` keyword argument helps you to achieve this.\n",
    "\n",
    "In the example below, we ask that `\"c1\"` is included in every specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sc.load_example_data1()\n",
    "x_exog = \"x1\"\n",
    "y_endog = \"y1\"\n",
    "controls = [\"c2\", \"group1\", \"group2\"]\n",
    "sco = sc.SpecificationCurve(df, y_endog, x_exog, controls, always_include=\"c1\")\n",
    "sco.fit()\n",
    "sco.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flexing the style for very large numbers of specifications\n",
    "\n",
    "The default plot type isn't suitable for very large numbers of specifications, but it does automatically switch to a style suited to a large number of specifications.\n",
    "\n",
    "Here's an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some fake data\n",
    "\n",
    "n_samples = 2000\n",
    "# Number of dimensions of continuous\n",
    "n_dim = 8\n",
    "c_rnd_vars = prng.random(size=(n_dim, n_samples))\n",
    "c_rnd_vars_names = [f\"c_{i}\" for i in range(np.shape(c_rnd_vars)[0])]\n",
    "y_1 = (\n",
    "    0.4 * c_rnd_vars[0, :]  # This is the true value of the coefficient\n",
    "    - 0.2 * c_rnd_vars[1, :]\n",
    "    + 0.3 * prng.standard_normal(n_samples)\n",
    ")\n",
    "# Next line causes y_2 ests to be much more noisy\n",
    "y_2 = y_1 - 0.3 * np.abs(prng.standard_normal(n_samples))\n",
    "df = pd.DataFrame([y_1, y_2], [\"y1\", \"y2\"]).T\n",
    "for i, col_name in enumerate(c_rnd_vars_names):\n",
    "    df[col_name] = c_rnd_vars[i, :]\n",
    "\n",
    "controls = c_rnd_vars_names[1:]\n",
    "\n",
    "# Run it with Specification Curve\n",
    "sco = sc.SpecificationCurve(df, [\"y1\", \"y2\"], c_rnd_vars_names[0], controls)\n",
    "sco.fit()\n",
    "sco.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flagging a preferred specification\n",
    "\n",
    "Often, in practice, you will have a *preferred* specification that you will use as your estimate. You can specify this and have it be flagged.\n",
    "\n",
    "You can achieve this by passing a list of variables that you'd like to be used in your preferred specification via the `preferred_spec` keyword argument.\n",
    "\n",
    "In the example below, the preferred specification comes out as being close to the known answer that we constructed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sco = sc.SpecificationCurve(df, [\"y1\", \"y2\"], c_rnd_vars_names[0], controls)\n",
    "sco.fit()\n",
    "sco.plot(preferred_spec=[\"y1\", c_rnd_vars_names[0]] + controls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using models other than Ordinary Least Squares\n",
    "\n",
    "The default model is OLS, but you can pass through other models too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the regressions to run\n",
    "y_endog = [\"y\", \"y2\"]\n",
    "x_exog = [\"x_1\", \"x_5\"]\n",
    "controls = [\"x_3\", \"x_2\", \"x_4\"]\n",
    "sco = sc.SpecificationCurve(df_logit, y_endog, x_exog, controls)\n",
    "# Fit using the logit estimator\n",
    "sco.fit(estimator=sm.Logit)  # sm.Probit also works\n",
    "sco.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
