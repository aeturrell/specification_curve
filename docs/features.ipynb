{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Features\"\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see some of **Specification Curve**'s features in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "\n",
    "import matplotlib_inline.backend_inline\n",
    "\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats(\"svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example of using **Specification Curve**. Note that, in the below, we can pass strings or lists of string into the arguments of the class `SpecificationCurve`. The programme then automatically performs all of possible regressions of endogeneous variables on exogeneous variables and controls. The estimate that is picked out is the coefficient on the given combination of endogeneous and exogenous variables (with conditioning on the given controls).\n",
    "\n",
    "If a control variable is categorical, rather than continuous, it will be treated as a fixed effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import specification_curve as specy\n",
    "\n",
    "df = specy.load_example_data1()\n",
    "y_endog = \"y1\"  # endogeneous variable\n",
    "x_exog = \"x1\"  # exogeneous variable\n",
    "controls = [\"c1\", \"c2\", \"group1\", \"group2\"]\n",
    "sc = specy.SpecificationCurve(\n",
    "    df,\n",
    "    y_endog,\n",
    "    x_exog,\n",
    "    controls,\n",
    ")\n",
    "sc.fit()\n",
    "sc.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grey squares (black lines when there are many specifications) show whether a variable is included in a specification or not. Blue or red markers and error bars show whether the coefficient is positive and significant (at the 0.05 level) or red and significant, respectively.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also specify models with the formula API. An example string would be \"y1 | y2 ~ x1 | x2 | x3 + c1 + c2 + c3 | c4\". This would produce a specification curve in which there two endogenous variables, two exogenous variables, two variables that are always included (c1 and c2), and two controls that are included in all possible combinations.\n",
    "\n",
    "Here's an example, for which we first generate some data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Set seed for random numbers\n",
    "seed_for_prng = 78557\n",
    "# prng=probabilistic random number generator\n",
    "prng = np.random.default_rng(seed_for_prng)\n",
    "\n",
    "# generate some fake data\n",
    "n_samples = 1000\n",
    "x_2 = prng.integers(2, size=n_samples)\n",
    "x_1 = prng.random(size=n_samples)\n",
    "x_3 = prng.integers(3, size=n_samples)\n",
    "x_4 = prng.random(size=n_samples)\n",
    "x_5 = x_1 + 0.05 * np.random.randn(n_samples)\n",
    "x_beta = -1 - 3.5 * x_1 + 0.2 * x_2 + 0.3 * x_3  # NB: coefficient is -3.5\n",
    "prob = 1 / (1 + np.exp(-x_beta))\n",
    "y = prng.binomial(n=1, p=prob, size=n_samples)\n",
    "y2 = prng.binomial(n=1, p=prob * 0.98, size=n_samples)\n",
    "df_logit = pd.DataFrame(\n",
    "    [x_1, x_2, x_3, x_4, x_5, y, y2], [\"x_1\", \"x_2\", \"x_3\", \"x_4\", \"x_5\", \"y\", \"y2\"]\n",
    ").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_form = specy.SpecificationCurve(\n",
    "    df_logit, formula=\"y | y2 ~ x_1 | x_5 + x_2 + x_3 | x_4\"\n",
    ")\n",
    "sc_form.fit()\n",
    "sc_form.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that \"x_2\" is included in all specifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving estimates\n",
    "\n",
    "You can retrieve the estimates from the data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = specy.SpecificationCurve(df, y_endog, x_exog, controls)\n",
    "sc.fit()\n",
    "sc.df_r.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving results to file\n",
    "\n",
    "Save the plot to file (the format is inferred from file extension):\n",
    "\n",
    "```python\n",
    "sc = specy.SpecificationCurve(df, y_endog, x_exog, controls,\n",
    "                                  cat_expand=['group1'])\n",
    "sc.fit()\n",
    "sc.plot(save_path='test_fig.pdf')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expanding a categorical variable\n",
    "\n",
    "Should you need to, you can expand a categorical variable into its different elements and run those separately. In the example below, the `\"group2\"` categorical variable is expanded like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_endog = \"y1\"  # endogeneous variable\n",
    "x_exog = \"x1\"  # exogeneous variable\n",
    "controls = [\"c1\", \"c2\", \"group1\", \"group2\"]\n",
    "sc = specy.SpecificationCurve(\n",
    "    df,\n",
    "    y_endog,\n",
    "    x_exog,\n",
    "    controls,\n",
    "    cat_expand=[\"group2\"],  # have each fixed effect run separately\n",
    ")\n",
    "sc.fit()\n",
    "sc.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using multiple exogeneous variables\n",
    "\n",
    "Sometimes, you'd like to check different independent variables (and the coefficients they come with following a regression). This is achieved by passing a list to the exogeneous argument of `SpecificationCurve`. These variations on the independent variables are labelled by `x` in the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = specy.load_example_data1()\n",
    "x_exog = [\"x1\", \"x2\"]\n",
    "y_endog = \"y1\"\n",
    "controls = [\"c1\", \"c2\", \"group1\", \"group2\"]\n",
    "sc = specy.SpecificationCurve(df, y_endog, x_exog, controls)\n",
    "sc.fit()\n",
    "sc.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excluding some combinations of controls\n",
    "\n",
    "Some controls may be redundant, and you might want to exclude them both being used together. The `exclu_grps` keyword argument achieves this.\n",
    "\n",
    "In the below example, `\"c1\"` and `\"c2\"` are never run in the same specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = specy.load_example_data1()\n",
    "\n",
    "y_endog = \"y1\"\n",
    "x_exog = \"x1\"\n",
    "controls = [\"c1\", \"c2\", \"group1\", \"group2\"]\n",
    "sc = specy.SpecificationCurve(df, y_endog, x_exog, controls, exclu_grps=[[\"c1\", \"c2\"]])\n",
    "sc.fit()\n",
    "sc.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Always include some controls in all specifications\n",
    "\n",
    "Likewise, there will be times when you always wish to include a particular control in specifications, and to show this on the plot. The `always_include=` keyword argument helps you to achieve this.\n",
    "\n",
    "In the example below, we ask that `\"c1\"` is included in every specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = specy.load_example_data1()\n",
    "x_exog = \"x1\"\n",
    "y_endog = \"y1\"\n",
    "controls = [\"c2\", \"group1\", \"group2\"]\n",
    "sc = specy.SpecificationCurve(df, y_endog, x_exog, controls, always_include=\"c1\")\n",
    "sc.fit()\n",
    "sc.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flexing the style for very large numbers of specifications\n",
    "\n",
    "The default plot type isn't suitable for very large numbers of specifications, but it does automatically switch to a style suited to a large number of specifications.\n",
    "\n",
    "Here's an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some fake data\n",
    "\n",
    "n_samples = 400\n",
    "# Number of dimensions of continuous\n",
    "n_dim = 8\n",
    "c_rnd_vars = prng.random(size=(n_dim, n_samples))\n",
    "c_rnd_vars_names = [f\"c_{i}\" for i in range(np.shape(c_rnd_vars)[0])]\n",
    "y_1 = (\n",
    "    0.4 * c_rnd_vars[0, :]  # This is the true value of the coefficient\n",
    "    - 0.2 * c_rnd_vars[1, :]\n",
    "    + 0.3 * prng.standard_normal(n_samples)\n",
    ")\n",
    "# Next line causes y_2 ests to be much more noisy\n",
    "y_2 = y_1 - 0.3 * np.abs(prng.standard_normal(n_samples))\n",
    "df = pd.DataFrame([y_1, y_2], [\"y1\", \"y2\"]).T\n",
    "for i, col_name in enumerate(c_rnd_vars_names):\n",
    "    df[col_name] = c_rnd_vars[i, :]\n",
    "\n",
    "controls = c_rnd_vars_names[1:]\n",
    "\n",
    "# Run it with Specification Curve\n",
    "sc = specy.SpecificationCurve(df, [\"y1\", \"y2\"], c_rnd_vars_names[0], controls)\n",
    "sc.fit()\n",
    "sc.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flagging a preferred specification\n",
    "\n",
    "Often, in practice, you will have a *preferred* specification that you will use as your estimate. You can specify this and have it be flagged.\n",
    "\n",
    "You can achieve this by passing a list of variables that you'd like to be used in your preferred specification via the `preferred_spec` keyword argument.\n",
    "\n",
    "In the example below, the preferred specification comes out as being close to the known answer that we constructed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = specy.SpecificationCurve(df, [\"y1\", \"y2\"], c_rnd_vars_names[0], controls)\n",
    "sc.fit()\n",
    "sc.plot(preferred_spec=[\"y1\", c_rnd_vars_names[0]] + controls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using models other than Ordinary Least Squares\n",
    "\n",
    "The default model is OLS, but you can pass through other models too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the regressions to run\n",
    "y_endog = [\"y\", \"y2\"]\n",
    "x_exog = [\"x_1\", \"x_5\"]\n",
    "controls = [\"x_3\", \"x_2\", \"x_4\"]\n",
    "sc = specy.SpecificationCurve(df_logit, y_endog, x_exog, controls)\n",
    "# Fit using the logit estimator\n",
    "sc.fit(estimator=sm.Logit)  # sm.Probit also works\n",
    "sc.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
